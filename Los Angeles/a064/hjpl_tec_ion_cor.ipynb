{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09b71d6f-56e8-47d7-b8d0-1971352f4a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/panda/eedy/ion_los-angle/s1_a064/notebook\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afc5146e-4f06-42ae-8156-f453c3c7605a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /home/eedy/tools/mambaforge/envs/insar/share/proj failed\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "############################################################\n",
    "# Program is part of MintPy                                #\n",
    "# Copyright (c) 2013, Zhang Yunjun, Heresh Fattahi         #\n",
    "# Author: Wang Yidi, May 2024                              #\n",
    "############################################################\n",
    "\n",
    "\n",
    "import os\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import interpolate\n",
    "from mintpy.objects import ionex, timeseries\n",
    "from mintpy.simulation import iono\n",
    "from mintpy.utils import readfile, writefile\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from tqdm import tqdm\n",
    "from mintpy import iono_tec\n",
    "from mintpy.cli import diff, ifgram_inversion, modify_network, reference_point, reference_date\n",
    "from mintpy.utils import utils as ut\n",
    "\n",
    "from datetime import datetime\n",
    "from netCDF4 import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2024bea9-5271-43d0-b847-b9d74379fbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌               | 257/293 [02:23<00:14,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encountered a ValueError: The points in dimension 0 must be strictly ascending or descending\n",
      "Skipping to the next iteration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 293/293 [02:39<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete exsited file: ../mintpy_hight_gim_ion_upsample/ion.h5\n",
      "create HDF5 file: ../mintpy_hight_gim_ion_upsample/ion.h5 with w mode\n",
      "create dataset /date       of |S8        in size of (293,)               with compression=None\n",
      "create dataset /timeseries of float32    in size of (293, 690, 229)      with compression=None\n",
      "finished writing to ../mintpy_hight_gim_ion_upsample/ion.h5\n"
     ]
    }
   ],
   "source": [
    "def compute_lat_lon_ipp(geo_file, utc_sec):\n",
    "    incidenceAngle = readfile.read(geo_file, datasetName='incidenceAngle')[0]\n",
    "    incidenceAngle = np.squeeze(incidenceAngle)\n",
    "    incidenceAngle[incidenceAngle == 0] = np.nan\n",
    "\n",
    "    azimuthAngle = readfile.read(geo_file, datasetName='azimuthAngle')[0]\n",
    "    azimuthAngle = np.squeeze(azimuthAngle)\n",
    "    azimuthAngle[azimuthAngle == 0] = np.nan\n",
    "\n",
    "    latitude = readfile.read(geo_file, datasetName='latitude')[0]\n",
    "    latitude = np.squeeze(latitude)\n",
    "    latitude[latitude == 0] = np.nan\n",
    "\n",
    "    longitude = readfile.read(geo_file, datasetName='longitude')[0]\n",
    "    longitude = np.squeeze(longitude)\n",
    "    longitude[longitude == 0] = np.nan\n",
    "    \n",
    "    theta = incidenceAngle*np.pi/180\n",
    "    Re = 6371000\n",
    "    h_ipp = 450e3\n",
    "    theta_ipp = np.arcsin(Re*np.sin(theta)/(Re+h_ipp))\n",
    "    HEADING = azimuthAngle*np.pi/180\n",
    "\n",
    "    alpha_ipp = theta - theta_ipp\n",
    "\n",
    "    latitude_pi = latitude *np.pi/180\n",
    "    longitude_pi = longitude *np.pi/180\n",
    "\n",
    "    lat_ipp_pi = np.arcsin(np.sin(latitude_pi)*np.cos(alpha_ipp) + np.cos(latitude_pi)*np.sin(alpha_ipp)*np.cos(HEADING))\n",
    "    atan2_func = np.vectorize(math.atan2)\n",
    "    delta = atan2_func(-np.sin(alpha_ipp)*np.cos(latitude_pi)*np.sin(HEADING), np.cos(alpha_ipp) - np.sin(latitude_pi)*np.sin(lat_ipp_pi))\n",
    "    lon_ipp_pi = np.mod(longitude_pi + delta + np.pi, 2*np.pi) - np.pi\n",
    "\n",
    "    lat_ipp = lat_ipp_pi *180/np.pi\n",
    "    lon_ipp = lon_ipp_pi *180/np.pi\n",
    "\n",
    "    return lat_ipp, lon_ipp ,theta_ipp\n",
    "\n",
    "def read_netcdf_file(filename):\n",
    "    # Open the NetCDF file for reading\n",
    "    dataset = Dataset(filename, 'r')\n",
    "\n",
    "    # Get the data variables\n",
    "    varepochs_data = dataset.variables['varepochs'][:]\n",
    "    time_data = dataset.variables['time'][:]\n",
    "    lats = dataset.variables['lat'][:]\n",
    "    lons = dataset.variables['lon'][:]\n",
    "    tec_maps = dataset.variables['tecmap'][:]\n",
    "    tec_flag = dataset.variables['tecflag'][:]\n",
    "\n",
    "    # Close the NetCDF file\n",
    "    dataset.close()\n",
    "\n",
    "    mins = []\n",
    "    for varepoch in varepochs_data:\n",
    "        dt = datetime.strptime(varepoch, \"%Y/%m/%d_%H:%M:%S\")\n",
    "        total_minutes = dt.hour * 60 + dt.minute + dt.second / 60\n",
    "        mins.append(total_minutes)\n",
    "    \n",
    "    # Return the data\n",
    "    return varepochs_data, time_data, lats, lons, tec_maps, tec_flag , mins\n",
    "\n",
    "def compute_r_iono(utc_sec, tec_file, lat_ipp, lon_ipp , theta_ipp, geo_file,times_path):\n",
    "    \n",
    "    varepochs, time, lats, lons, tec_maps, tecflag , mins= read_netcdf_file(tec_file)\n",
    "    \n",
    "    minutes1 = utc_sec / 60\n",
    "    for i in range(len(mins) - 1):\n",
    "        if minutes1 >= mins[i] and minutes1 <= mins[i+1]:\n",
    "            break\n",
    "\n",
    "    valid_mask = ~(np.isnan(lat_ipp) | np.isnan(lon_ipp))\n",
    "    valid_lat_ipp = lat_ipp[valid_mask]\n",
    "    valid_lon_ipp = lon_ipp[valid_mask]\n",
    "\n",
    "    interp_func = RegularGridInterpolator((mins, lats, lons), tec_maps, method='linear')\n",
    "\n",
    "    Ei = np.column_stack((np.full(valid_lat_ipp.size, mins[i]),\n",
    "                          valid_lat_ipp,\n",
    "                          valid_lon_ipp + (minutes1 - mins[i]) * 360. / (24. * 60.)))\n",
    "\n",
    "    Ei1 = np.column_stack((np.full(valid_lat_ipp.size, mins[i+1]),\n",
    "                           valid_lat_ipp,\n",
    "                           valid_lon_ipp + (minutes1 - mins[i+1]) * 360. / (24. * 60.)))\n",
    "\n",
    "    new_tec_map1 = np.full_like(lat_ipp, np.nan)\n",
    "    new_tec_map1[valid_mask] = ((mins[i+1] - minutes1) / (mins[i+1] - mins[i]) * interp_func(Ei) + (minutes1 - mins[i]) / (mins[i+1] - mins[i]) * interp_func(Ei1))\n",
    "\n",
    "    k = 40.31\n",
    "    c = 299792458\n",
    "    meta = readfile.read_attribute(times_path)\n",
    "    freq = c / float(meta['WAVELENGTH'])\n",
    "    h_ipp = 450e3\n",
    "    Re = 6371000\n",
    "   \n",
    "    VTEC = new_tec_map1*1e16\n",
    "    a = VTEC * k / (freq ** 2)\n",
    "    r_iono = a / np.cos(np.arcsin(np.sin(theta_ipp) / (1 + a)))\n",
    "    \n",
    "    return r_iono\n",
    "\n",
    "def create_iono_timeseries(times_path, tec_dir, geo_file, iono_file):\n",
    "    \n",
    "    # download\n",
    "    date_list = timeseries(times_path).get_date_list()\n",
    "    tec_files = [f\"{tec_dir}/jpld{datetime.strptime(date, '%Y%m%d').timetuple().tm_yday:03d}0.{date[2:4]}i.nc\" for date in date_list]\n",
    "    \n",
    "    # run\n",
    "    meta = readfile.read_attribute(times_path)\n",
    "    utc_sec = float(meta['CENTER_LINE_UTC'])\n",
    "    lat_ipp, lon_ipp ,theta_ipp = compute_lat_lon_ipp(geo_file, utc_sec)\n",
    "    \n",
    "    # write\n",
    "    num_files = len(tec_files)\n",
    "    meta = readfile.read_attribute(geo_file)\n",
    "    width = int(meta['WIDTH'])\n",
    "    length = int(meta['LENGTH'])\n",
    "    r_iono = np.zeros((num_files, length,width), dtype=np.float32)\n",
    "    \n",
    "    for i in tqdm(range(num_files)):\n",
    "        try:\n",
    "            r_iono[i,:,:] = compute_r_iono(utc_sec, tec_files[i], lat_ipp, lon_ipp , theta_ipp, geo_file,times_path)\n",
    "        except ValueError as e:\n",
    "            print(f\"Encountered a ValueError: {e}\")\n",
    "            print(\"Skipping to the next iteration...\")\n",
    "            continue\n",
    "\n",
    "    meta = readfile.read_attribute(times_path)\n",
    "    ref = meta['REF_DATE']\n",
    "    \n",
    "    for i_date_ion in range(len(date_list) - 1):\n",
    "        if ref == date_list[i_date_ion]: \n",
    "            break\n",
    "            \n",
    "    r_iono[:,:,:] = r_iono[:,:,:] - r_iono[i_date_ion,:,:]\n",
    "\n",
    "    ref_y = int(meta['REF_Y'])\n",
    "    ref_x = int(meta['REF_X'])\n",
    "    r_iono[:,:,:] = r_iono[:,:,:] - r_iono[:,ref_y,ref_x][:, None, None]\n",
    "    \n",
    "    # prepare meta\n",
    "    meta = readfile.read_attribute(times_path)\n",
    "    meta['FILE_TYPE'] = 'timeseries'\n",
    "    meta['UNIT'] = 'm'\n",
    "    # absolute delay without double reference\n",
    "    #for key in ['REF_X','REF_Y','REF_LAT','REF_LON','REF_DATE']:\n",
    "        #if key in meta.keys():\n",
    "            #meta.pop(key)\n",
    "\n",
    "    ds_dict = {}\n",
    "    ds_dict['date'] = np.array(date_list, dtype=np.string_)\n",
    "    ds_dict['timeseries'] = r_iono\n",
    "    \n",
    "    writefile.write(ds_dict, iono_file, metadata=meta)\n",
    "    return iono_file\n",
    "\n",
    "\n",
    "dis_file = '../mintpy_hight_gim_ion_upsample/timeseries.h5'\n",
    "tec_dir =  '/home/eedy/data/aux/IONEX'\n",
    "geo_file = '../mintpy_hight_gim_ion_upsample/inputs/geometryRadar.h5'\n",
    "iono_file = '../mintpy_hight_gim_ion_upsample/ion.h5'\n",
    "\n",
    "ion = create_iono_timeseries(dis_file, tec_dir, geo_file, iono_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d1e94bd-c5be-449d-99d0-44490c7fce14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../mintpy_hight_gim_ion_upsample/timeseries_SET.h5 - ['../mintpy_hight_gim_ion_upsample/ion.h5'] --> ../mintpy_hight_gim_ion_upsample/timeseries_SET_ion.h5\n",
      "the 1st input file is: timeseries\n",
      "--------------------------------------------------\n",
      "grab metadata from ref_file: ../mintpy_hight_gim_ion_upsample/timeseries_SET.h5\n",
      "grab dataset structure from ref_file: ../mintpy_hight_gim_ion_upsample/timeseries_SET.h5\n",
      "create HDF5 file: ../mintpy_hight_gim_ion_upsample/timeseries_SET_ion.h5 with w mode\n",
      "create dataset  : bperp      of float32                   in size of (293,)               with compression = None\n",
      "create dataset  : date       of |S8                       in size of (293,)               with compression = None\n",
      "create dataset  : timeseries of float32                   in size of (293, 690, 229)      with compression = None\n",
      "close  HDF5 file: ../mintpy_hight_gim_ion_upsample/timeseries_SET_ion.h5\n",
      "read from file: ../mintpy_hight_gim_ion_upsample/ion.h5\n",
      "read from file: ../mintpy_hight_gim_ion_upsample/timeseries_SET.h5\n",
      "--------------------------------------------------\n",
      "open  HDF5 file ../mintpy_hight_gim_ion_upsample/timeseries_SET_ion.h5 in a mode\n",
      "writing dataset /timeseries                block: [0, 293, 0, 690, 0, 229]\n",
      "close HDF5 file ../mintpy_hight_gim_ion_upsample/timeseries_SET_ion.h5.\n",
      "time used: 00 mins 2.3 secs\n"
     ]
    }
   ],
   "source": [
    "!diff.py ../mintpy_hight_gim_ion_upsample/timeseries_SET.h5 ../mintpy_hight_gim_ion_upsample/ion.h5 -o ../mintpy_hight_gim_ion_upsample/timeseries_SET_ion.h5 --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e815d14e-61cb-426a-8d5a-5888cf377883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
