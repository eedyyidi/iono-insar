{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4f5217-4692-4da9-bb97-1728c93860ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514924e4-5982-4659-b4ef-9e79c3cdf07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "############################################################\n",
    "# Program is part of MintPy                                #\n",
    "# Copyright (c) 2013, Zhang Yunjun, Heresh Fattahi         #\n",
    "# Author: Wang Yidi, May 2024                              #\n",
    "############################################################\n",
    "\n",
    "\n",
    "import os\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import interpolate\n",
    "from mintpy.objects import ionex, timeseries\n",
    "from mintpy.simulation import iono\n",
    "from mintpy.utils import readfile, writefile\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from tqdm import tqdm\n",
    "from mintpy import iono_tec\n",
    "from mintpy.cli import diff, ifgram_inversion, modify_network, reference_point, reference_date\n",
    "from mintpy.utils import utils as ut\n",
    "\n",
    "from datetime import datetime\n",
    "from netCDF4 import Dataset\n",
    "import glob\n",
    "from scipy.signal import convolve2d\n",
    "from mintpy.objects import ramp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8d3308-aa88-46c0-b071-a3f26bf3605e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_lat_lon_ipp(geo_file, utc_sec):\n",
    "    incidenceAngle = readfile.read(geo_file, datasetName='incidenceAngle')[0]\n",
    "    incidenceAngle = np.squeeze(incidenceAngle)\n",
    "    incidenceAngle[incidenceAngle == 0] = np.nan\n",
    "\n",
    "    azimuthAngle = readfile.read(geo_file, datasetName='azimuthAngle')[0]\n",
    "    azimuthAngle = np.squeeze(azimuthAngle)\n",
    "    azimuthAngle[azimuthAngle == 0] = np.nan\n",
    "\n",
    "    latitude = readfile.read(geo_file, datasetName='latitude')[0]\n",
    "    latitude = np.squeeze(latitude)\n",
    "    latitude[latitude == 0] = np.nan\n",
    "\n",
    "    longitude = readfile.read(geo_file, datasetName='longitude')[0]\n",
    "    longitude = np.squeeze(longitude)\n",
    "    longitude[longitude == 0] = np.nan\n",
    "    \n",
    "    theta = incidenceAngle*np.pi/180\n",
    "    Re = 6371000\n",
    "    h_ipp = 450e3\n",
    "    theta_ipp = np.arcsin(Re*np.sin(theta)/(Re+h_ipp))\n",
    "    HEADING = azimuthAngle*np.pi/180\n",
    "\n",
    "    alpha_ipp = theta - theta_ipp\n",
    "\n",
    "    latitude_pi = latitude *np.pi/180\n",
    "    longitude_pi = longitude *np.pi/180\n",
    "\n",
    "    lat_ipp_pi = np.arcsin(np.sin(latitude_pi)*np.cos(alpha_ipp) + np.cos(latitude_pi)*np.sin(alpha_ipp)*np.cos(HEADING))\n",
    "    atan2_func = np.vectorize(math.atan2)\n",
    "    delta = atan2_func(-np.sin(alpha_ipp)*np.cos(latitude_pi)*np.sin(HEADING), np.cos(alpha_ipp) - np.sin(latitude_pi)*np.sin(lat_ipp_pi))\n",
    "    lon_ipp_pi = np.mod(longitude_pi + delta + np.pi, 2*np.pi) - np.pi\n",
    "\n",
    "    lat_ipp = lat_ipp_pi *180/np.pi\n",
    "    lon_ipp = lon_ipp_pi *180/np.pi\n",
    "\n",
    "    return lat_ipp, lon_ipp ,theta_ipp\n",
    "\n",
    "def read_netcdf_file(filename):\n",
    "    dataset = Dataset(filename, 'r')\n",
    "    lats = dataset.variables['gdlat'][:] #纬度\n",
    "    lons = dataset.variables['glon'][:] #精度\n",
    "    tec_maps = dataset.variables['tec'][:] #这个看起来是我想要的\n",
    "    dataset.close()\n",
    "    mins = np.arange(0, 24 * 60, 5)\n",
    "    # Return the data\n",
    "    return lats, lons, tec_maps , mins\n",
    "\n",
    "def compute_r_iono(utc_sec, tec_file, lat_ipp, lon_ipp , theta_ipp, geo_file,times_path):\n",
    "    \n",
    "    lats, lons, tec_maps,mins= read_netcdf_file(tec_file)\n",
    "    kernel = np.ones((5, 5)) / 25\n",
    "    \n",
    "    for i in tqdm(range(tec_maps.shape[0])):\n",
    "        tec_maps[i, :, :] = convolve2d(tec_maps[i, :, :], kernel, mode='same', boundary='wrap')\n",
    "    \n",
    "    minutes1 = utc_sec / 60\n",
    "    for i in range(len(mins) - 1):\n",
    "        if minutes1 >= mins[i] and minutes1 <= mins[i+1]:\n",
    "            break\n",
    "\n",
    "    valid_mask = ~(np.isnan(lat_ipp) | np.isnan(lon_ipp))\n",
    "    valid_lat_ipp = lat_ipp[valid_mask]\n",
    "    valid_lon_ipp = lon_ipp[valid_mask]\n",
    "\n",
    "    interp_func = RegularGridInterpolator((mins, lats, lons), tec_maps, method='linear')\n",
    "\n",
    "    Ei = np.column_stack((np.full(valid_lat_ipp.size, mins[i]),\n",
    "                          valid_lat_ipp,\n",
    "                          valid_lon_ipp + (minutes1 - mins[i]) * 360. / (24. * 60.)))\n",
    "\n",
    "    Ei1 = np.column_stack((np.full(valid_lat_ipp.size, mins[i+1]),\n",
    "                           valid_lat_ipp,\n",
    "                           valid_lon_ipp + (minutes1 - mins[i+1]) * 360. / (24. * 60.)))\n",
    "\n",
    "    new_tec_map1 = np.full_like(lat_ipp, np.nan)\n",
    "    new_tec_map1[valid_mask] = ((mins[i+1] - minutes1) / (mins[i+1] - mins[i]) * interp_func(Ei) + (minutes1 - mins[i]) / (mins[i+1] - mins[i]) * interp_func(Ei1))\n",
    "\n",
    "    k = 40.31\n",
    "    c = 299792458\n",
    "    meta = readfile.read_attribute(times_path)\n",
    "    freq = c / float(meta['WAVELENGTH'])\n",
    "    h_ipp = 450e3\n",
    "    Re = 6371000\n",
    "   \n",
    "    VTEC = new_tec_map1*1e16\n",
    "    a = VTEC * k / (freq ** 2)\n",
    "    r_iono = a / np.cos(np.arcsin(np.sin(theta_ipp) / (1 + a)))\n",
    "    \n",
    "    return r_iono\n",
    "\n",
    "def create_iono_timeseries(times_path, tec_dir, geo_file, iono_file):\n",
    "    \n",
    "    # download\n",
    "    date_list = timeseries(times_path).get_date_list()\n",
    "    tec_files_pattern = [f\"{tec_dir}/gps{date[2:8]}g.*.*\" for date in date_list]\n",
    "    tec_files = []\n",
    "    for pattern in tec_files_pattern:\n",
    "        files = glob.glob(pattern)\n",
    "        tec_files.extend(files)\n",
    "\n",
    "        \n",
    "    # run\n",
    "    meta = readfile.read_attribute(times_path)\n",
    "    utc_sec = float(meta['CENTER_LINE_UTC'])\n",
    "    lat_ipp, lon_ipp ,theta_ipp = compute_lat_lon_ipp(geo_file, utc_sec)\n",
    "    \n",
    "    # write\n",
    "    num_files = len(tec_files)\n",
    "    meta = readfile.read_attribute(geo_file)\n",
    "    width = int(meta['WIDTH'])\n",
    "    length = int(meta['LENGTH'])\n",
    "    r_iono = np.zeros((num_files, length,width), dtype=np.float32)\n",
    "\n",
    "    for i in tqdm(range(num_files)):\n",
    "        try:\n",
    "            r_iono[i,:,:] = compute_r_iono(utc_sec, tec_files[i], lat_ipp, lon_ipp , theta_ipp, geo_file,times_path)\n",
    "        except ValueError as e:\n",
    "            print(f\"Encountered a ValueError: {e}\")\n",
    "            print(\"Skipping to the next iteration...\")\n",
    "            continue\n",
    "\n",
    "    meta = readfile.read_attribute(times_path)\n",
    "    ref = meta['REF_DATE']\n",
    "    \n",
    "    for i_date_ion in range(len(date_list) - 1):\n",
    "        if ref == date_list[i_date_ion]: \n",
    "            break\n",
    "            \n",
    "    r_iono[:,:,:] = r_iono[:,:,:] - r_iono[i_date_ion,:,:]\n",
    "\n",
    "    ref_y = int(meta['REF_Y'])\n",
    "    ref_x = int(meta['REF_X'])\n",
    "    r_iono[:,:,:] = r_iono[:,:,:] - r_iono[:,ref_y,ref_x][:, None, None]\n",
    "\n",
    "    data_out, r_iono = ramp.deramp(r_iono, mask_in=None, ramp_type='linear', metadata=None, max_num_sample=1e3, coeff_file=None,ignore_zero_value=True)\n",
    "    \n",
    "    # prepare meta\n",
    "    meta = readfile.read_attribute(times_path)\n",
    "    meta['FILE_TYPE'] = 'timeseries'\n",
    "    meta['UNIT'] = 'm'\n",
    "    # absolute delay without double reference\n",
    "    #for key in ['REF_X','REF_Y','REF_LAT','REF_LON','REF_DATE']:\n",
    "        #if key in meta.keys():\n",
    "            #meta.pop(key)\n",
    "\n",
    "    ds_dict = {}\n",
    "    ds_dict['date'] = np.array(date_list, dtype=np.string_)\n",
    "    ds_dict['timeseries'] = r_iono\n",
    "    \n",
    "    writefile.write(ds_dict, iono_file, metadata=meta)\n",
    "    return iono_file\n",
    "\n",
    "\n",
    "dis_file = '../mintpy_MIT_gim_ion_upsample_new/timeseries.h5'\n",
    "tec_dir =  '/home/eedy/data/aux/IONEX'\n",
    "geo_file = '../mintpy_MIT_gim_ion_upsample/inputs/geometryRadar.h5'\n",
    "iono_file = '../mintpy_MIT_gim_ion_upsample_new/ion.h5'\n",
    "\n",
    "ion = create_iono_timeseries(dis_file, tec_dir, geo_file, iono_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4242bc4a-c35a-4361-9869-9fab7899bd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!diff.py ../mintpy_MIT_gim_ion_upsample_new/timeseries_SET.h5 ../mintpy_MIT_gim_ion_upsample_new/ion.h5 -o ../mintpy_MIT_gim_ion_upsample_new/timeseries_SET_ion.h5 --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfb67b5-be29-48b3-b74c-9f86ba5afb72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
